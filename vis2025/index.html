<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Input Visualization Workshop - IEEE VIS 2025</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href='//fonts.googleapis.com/css?family=Raleway:400,300,600' rel='stylesheet' type='text/css'>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="dist/css/normalize.css">
  <link rel="stylesheet" href="dist/css/skeleton.css">
  <link rel="stylesheet" href="css/custom.css">

  <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
  <script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js"></script>
  <link rel="stylesheet" href="css/github-prettify-theme.css">
  <script src="js/site.js"></script>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="dist/images/favicon.png">

</head>
<body class="code-snippets-visible">

  <!-- Primary Page Layout  
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <section class="header" style="margin-top:50px">
      <h2 class="title">Input Visualization Workshop</h2>
       <h5 class="title">IEEE VIS 2025 - Vienna, Austria, EU</h5>
       <h6 class="title">November 2 to 7, 2025 (UTC+1) Vienna, Austria, EU </h6> 
    </section>

    <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href="#Call">Call</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#Program"> Program</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#Committee"> Committee</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#Proceedings"> Proceedings</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#Organizers">Organizers</a></li>
          <li class="navbar-item"><a class="navbar-link" style="color:#b509ac" href="https://forms.gle/1wfQaVYrJc1eGzeWA" target="_blank">Submit</a></li>
        </ul>
      </div>
    </nav>
    
    <div class="docs-section" id="intro">
        <p>
Input visualization --- ``<i>visual representations that are designed to collect (and represent) new data rather than encode preexisting datasets</i>'' --- provides a new lens for direct interactions with data through visualizations and physicalizations. This visualization paradigm opens up new opportunities to collect data for data analysis, digital civics, decision making, personal informatics, data discussion, planning, organization, and more. However, despite nascent research on data input in information visualization, there is a lack of understanding of the phenomenon broadly and the implications for designing new input visualization systems. In this workshop, we aim to gather the human-computer interaction, visualization, and physicalization community to establish a research agenda for input visualization and outline the challenges and opportunities offered by this approach. 
     
        <img class="value-img" src="dist/images/input-visualization-pipeline-teaser.jpg" width="100%"
        <img class="value-img" src="dist/images/input-visualization-examples.jpg" width="100%"

          </p>
    </div>


    <!-- Why use Skeleton 
    -->
    <div class="docs-section" id="Call">
      <h6 class="docs-header">Call for Participation</h6>
      <p>

        We invite three types of submissions for the workshop: (1) Position papers, (2) Examples of input visualizations, (3) Expressions of interest to participate in the workshop without submitting a paper or example to help us estimate the number of attendees.
      </p>
      <p>
       <b>(1) Position papers:</b>
        We invite 2+ page position papers or pictorials that identify, highlight, or address key challenges related to interaction and input in visualizations, including (but not limited to):
      <ul>
        <li> New or existing input visualization designs.
        <li> New or overlooked use cases for interaction in visualizations.
        <li> Case studies of participatory visualization and physicalization in practice.
        <li> New interaction techniques for inputting, modifying, or annotating data via visual interfaces.
        <li> Novel physical, tangible, or tool-driven approaches to interacting with visualizations.
        <li> Design principles, challenges, or opportunities for interactive visualizations.
        </ul>
      Submissions should use the VGTC conference two-column format or DIS Pictorial format. Submissions will be shared with participants before the workshop. At least one author of each accepted paper must attend the workshop and must register for at least one day of the conference. 
      </p>
<p>
  <b><strike>Initial Submission deadline: August 4, 2025</strike></b><br/>
  <b>Extended Submission deadline: <span style="color:#b509ac">August 11, 2025</span></b><br/>
  <b>Notification: August 19, 2025</b>
</p>

<p>
<b>(2) Examples of input visualizations:</b>
Alternatively, we also invite submissions of examples of input visualizations that you find inspiring or relevant, whether from your own research or other sources. We will use these examples during the workshop as we aim to expand our evolving corpus of input visualizations. Please include an image and a short description of the example, as well as an explanation of why you find this example interesting or inspiring. Submissions should be provided in PDF format, or any other format the fits your submission.
</p>

<p>
<b>(3) Expressions of interest to participate:</b>
If you are interested in participating in the workshop, even without submitting a position paper or example, please fill out the form as well, as this will help us estimate the number of attendees.
</p>

        <!--
      Input visualization — provides a new lens for direct interactions with data through visualizations, opening new
      opportunities for engaging with data in analytic, civic, personal, and social contexts. However, there is not yet an
      established understanding of this approach or how to best design new input visualizations. This workshop aims to
      gather experts in interaction, visualization, and physicalization to identify important theoretical and practical challenges
      for input visualizations and map a research agenda for the field.
      We invite 2+ page position papers or pictorials that identify, highlight, or address key challenges related to interaction
      and input in visualizations, including (but not limited to):
      <ul>
        <li> New or existing input visualization designs.</li>
        <li> New or overlooked use cases for interaction in visualizations.
        <li> Case studies of participatory visualization and physicalization in practice.</li>
        <li> New interaction techniques for inputting, modifying, or annotating data via visual interfaces.</li>
        <li> Novel physical, tangible, or tool-driven approaches to interacting with visualizations.</li>
        <li> Design principles, challenges, or opportunities for interactive visualizations.</li>
      </ul>
      Submissions should use the single-column CHI format and be submitted through the workshop’s website. Accepted
      papers will be selected based on their potential to contribute to discussions, and all accepted submissions will be shared
      with participants before the workshop. At least one author of each accepted paper must attend the workshop and must
      register for both the workshop and at least one day of the conference.
  -->
      </p>
      <p><a href="https://forms.gle/1wfQaVYrJc1eGzeWA">Submit here!</a>   </p>

    </div>

    <!-- Why use Skeleton 
    -->
    <div class="docs-section" id="Program">
      <h6 class="docs-header">Program</h6>

      <p>
        It is a one-day workshop. 
      <ul>  
        <li><b>Introduction (15min)</b></li>
        <li><b>Lightning Talks (60 min)</b></li>
        <li><b>Coffee Break</b></li>
        <li><b>Input Visualization Activity (60min)</b></li>
        <li><b>Lunch break</b></li>
        <li><b>Presentation and Synthesis of Groups' Visualizations (30 min)</b></li>
        <li><b>Refining Research Challenges and Questions (60 min)</b></li>
        <li><b>Coffee Break</b></li>
        <li><b>Outlining a Research Agenda (60 min)</b></li> 
        <li><b>Closing (15 min)</b></li>
      </ul>

      </p>

      </p>
    </div>

    <!-- Tables -->
    <div class="docs-section" id="Proceedings">
      <h6 class="docs-header">Proceedings</h6>
       <ul>  
        <li><a href="https://osf.io/g5ws3"  target="_blank">Jonathan Schwabish. 2025. Accessible Data Physicalization: Simple, Participatory Approaches in the Workplace. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a></li>
        <li><a href="https://osf.io/98pu5"  target="_blank">Madhav Poddar and Fabian Beck. 2025. Toward a Categorization of viaWidgets: Inline Widgets Leveraging Visualization for Interaction Augmentation. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/avhpj"  target="_blank">Michael Oppermann, Beatrix Wais-Zechmann, and Diotima Bertel. 2025. Input as Translation: Bridging Chronic Pain Experience and Clinical Understanding Through Visualization. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/efswp"  target="_blank">Ryan Smith. 2025. Position Paper: Potential Areas of Bias in Visualization-as-Input Systems. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/8p2gk"  target="_blank">Valeria Garro. 2025. The Role of Input Visualizations in Group Decision Making. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/5aed4"  target="_blank">Nikolaus Piccolotto, Fatih Öztank, Silvia Miksch, and Markus Bögl. 2025. Towards Visualization-Supported Uncertainty Elicitation. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/jnzdg"  target="_blank">Mirela Reljan-Delaney, Jo Wood, Alex Taylor, and Jason Dykes. 2025. Between Participatory Mapping and Input Visualisation: Creating Knowledge Through Interaction. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/t85ah"  target="_blank">Jakub Swacha and Michał Gracel. 2025. Two-Dimensional Game-Inspired Input Data Visualization for Multi-Aspectual Online Customer Feedback. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/3cyzw"  target="_blank">Bahare Bakhtiari, Sowmya Somanath, and Charles Perin. 2025. Repeated Actions in Fabric Manipulation Crafts as an Opportunity for Input Physicalization. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/ad7py"  target="_blank">Maryam Rezaie and Sheelagh Carpendale. 2025. Encoding Future Intent Through Pulling Interactions in Input Visualizations. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/8dwk4"  target="_blank">Foroozan Daneshzand and Sheelagh Carpendale. 2025. Quiet Input: Exploring Less-Intrusive, Low-Effort Modalities for Data Entry. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/tc9r6"  target="_blank">Rahul Bhargava, Sydney K. Purdue, Laura J. Perovich, Dani Snyder-Young, Alayt Issak, Michael Arnold Mages, Moira Zellner, Dean Massey, Geneliz Herrera.  2025. Data TheatreData Theatre as Input Visualization: as Input Visualization:Building Community Voice Building Community Voice and Cohesionand Cohesion. IEEE VIS 2025</a> </li>
</a> </li>
        <li><a href="https://osf.io/tchfg"  target="_blank">Eugenie Brasier, Martin Hachet, Pierre Dragicevic, and Yvonne Jansen. 2025. An Exploration of Engaging People in Daily Participatory Data Physicalization Tools. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/pjqdg"  target="_blank">Alexander Rind and Julia Boeck. 2025. Visual Tools for Input and Reflection in Social Work. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/56r3w"  target="_blank">Rimika Chaudhury, Sheelagh Carpendale, and Parmit K. Chilana. 2025. MILESTONES as an Input Visualization: The Design of a Self-Monitoring Tool for Self-Directed Learning. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
        <li><a href="https://osf.io/48ypv"  target="_blank">Mandy Keck, Magdalena Boucher, and Christina Stoiber. 2025. Bisous de Données: A Multisensory and Participatory Data Experience. In Proceedings of the Workshop on Envisioning a Research Agenda for Input Visualization. IEEE VIS 2025.
</a> </li>
       
       </ul>
    </div>
    
    <!-- Tables -->
    <div class="docs-section" id="Committee">
      <h6 class="docs-header">Committee</h6>
      <ul>  
        <li><a href="https://benjbach.github.io/"  target="_blank">Benjamin Bach, INRIA, France</a></li>
        <li><a href="https://camd.northeastern.edu/people/rahul-bhargava/"  target="_blank">Rahul Bhargava, Northeastern University, USA</a></li>
        <li><a href="http://sheelaghcarpendale.ca/"  target="_blank">Sheelagh Carpendale, Simon Fraser University, Canada</a></li>
        <li><a href="https://scholar.google.com/citations?user=UDhrduEAAAAJ&hl=en" target="_blank">Sarah Hayes, Munster Technological University, Ireland</a></li>
        <li><a href="https://yvonnejansen.fr/" target="_blank">Yvonne Jansen, CNRS, France</a></li>
        <li><a href="https://groups.cs.umass.edu/nmahyar/" target="_blank">Narges Mahyar, City St George's, University of London, UK</a></li>
        <li><a href="https://www.ocadu.ca/academics/explore-faculty/imeirelles" target="_blank">Isabel Meirelles, OCAD University, Canada</a></li>
        <li><a href="https://scholar.google.com.br/citations?user=QikAoAUAAAAJ&hl=pt-BR" target="_blank">Luiz Morais, UFPE, Brazil</a></li>
        <li><a href="https://services.informatik.hs-mannheim.de/~nagel/" target="_blank">Till Nagel,  Technical Hochschule Mannheim, Germany</a></li>
        <li><a href="https://www.kcl.ac.uk/people/georgia-panagiotidou" target="_blank">Georgia Panagiotidou, University of London, UK</a></li>
        <li><a href="https://evanpeck.github.io/" target="_blank">Evan Peck, University of Colorado Boulder, USA</a></li>
        <li><a href="http://charlesperin.net/" target="_blank">Charles Perin, University of Victoria, Canada</a></li>
        <li><a href="https://policyviz.com/about/" target="_blank">Jonathan Schwabish, The Urban Institute, USA</a></li>
        <li><a href="https://zezhongwang.com/" target="_blank">Zezhong Wang, Simon Fraser University, Canada </a></li>
      </ul>
    </div>





    <div class="docs-section" id="organizers">

      <h6 class="docs-header">ORGANIZERS</h6>
      
      <div class="value-props row" style="margin-top:10px;">

        <div class="two columns value-prop">
          <img class="value-img" src="dist/images/fig_nathalie.jpg" width="101">
            <a href="http://tactiledata.net"  target="_blank">Nathalie Bressa,<br/>Télécom Paris</a>
        </div>

        <div class="two columns value-prop">
          <img class="value-img" src="dist/images/Sam.jpg" width="101">
            <a href="https://samuel-huron.github.io/"  target="_blank">Samuel Huron,<br/>Télécom Paris</a> 
        </div>
        
        <div class="two columns value-prop">
          <img class="value-img" src="dist/images/Wes.jpg" width="101">
            <a href="https://www.wjwillett.net/"  target="_blank">Wesley Willett,<br/> University of Calgary</a> 
        </div>

        <div class="two columns value-prop">
          <img class="value-img" src="dist/images/evanthia.png" width="101">
            <a href="https://www.evanthiadimara.com/"  target="_blank">Evanthia Dimara,<br/> Utrecht University</a> 
        </div>      

        <div class="two columns value-prop">
          <img class="value-img" src="dist/images/Kim.jpg" width="101px">
            <a href="https://www.kimsauve.nl/"  target="_blank">Kim Sauvé,<br/> UWE Bristol</a> 
        </div>      

        <div class="two columns value-prop">
          <img class="value-img" src="dist/images/Derya.png" width="101px">
            <a href="https://gotdairyya.github.io/"  target="_blank">Derya Akbaba,<br/> Linköping University</a> 
        </div>      
      </div>


          <div class="docs-section" id="end">
              Made with love <3 
          </div>
    </section>


<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
